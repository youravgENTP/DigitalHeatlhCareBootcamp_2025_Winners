{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "id": "imports",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from CustomDataset import CustomImageDataset\n",
        "from Models import ResNet50, ResNet101, ResNet50_MCDropout\n",
        "from utils.Plots import (\n",
        "    plot_confusion, plot_roc, reliability_diagram,\n",
        "    expected_calibration_error, brier_score, entropy_hist\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "id": "config",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Configuration\n",
        "mode = \"Binary\"                 # e.g., \"Binary\", \"External\", \"Merged\"\n",
        "model_name = \"resnet50\"         # \"resnet50\" | \"resnet101\" | \"resnet50_mcdo\"\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "seed = 777\n",
        "save_dir = \"results/baseline\""
      ]
    },
    {
      "cell_type": "code",
      "id": "sanity-check",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Dataset sanity check (uses CustomDataset defaults)\n",
        "ds_train = CustomImageDataset(mode=mode, build_div='train')\n",
        "ds_val   = CustomImageDataset(mode=mode, build_div='val')\n",
        "ds_test  = CustomImageDataset(mode=mode, build_div='test')\n",
        "print(f\"Train: {len(ds_train)}, Val: {len(ds_val)}, Test: {len(ds_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "id": "build-model",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Model instantiation\n",
        "if model_name.lower() == \"resnet50\":\n",
        "    model = ResNet50(input_channel=3, label_num=1)\n",
        "elif model_name.lower() == \"resnet101\":\n",
        "    model = ResNet101(input_channel=3, label_num=1)\n",
        "elif model_name.lower() in (\"resnet50_mcdo\", \"resnet50_mcdropout\"):\n",
        "    model = ResNet50_MCDropout(input_channel=3, label_num=1)\n",
        "else:\n",
        "    raise ValueError(f\"Unknown model type: {model_name}\")\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "id": "train",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Training (simple, readable loop)\n",
        "import os\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "torch.manual_seed(seed); np.random.seed(seed)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "train_loader = DataLoader(ds_train, batch_size=batch_size, shuffle=True)\n",
        "val_loader   = DataLoader(ds_val,   batch_size=batch_size, shuffle=False)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    model.train(); running_loss = 0.0; correct = 0\n",
        "    for x, y in train_loader:\n",
        "        x = x.to(device); y = y.to(device).float().unsqueeze(1)\n",
        "        logits = model(x)\n",
        "        loss = criterion(logits, y)\n",
        "        optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        correct += ((torch.sigmoid(logits) >= 0.5).int() == y.int()).sum().item()\n",
        "    print(f\"Epoch {epoch}/{epochs} | loss={running_loss/len(train_loader):.4f} | acc={correct/len(ds_train):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "id": "validate-save",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Validation & save best\n",
        "model.eval(); val_loss = 0.0; correct = 0\n",
        "with torch.no_grad():\n",
        "    for x, y in val_loader:\n",
        "        x = x.to(device); y = y.to(device).float().unsqueeze(1)\n",
        "        logits = model(x)\n",
        "        val_loss += criterion(logits, y).item()\n",
        "        correct += ((torch.sigmoid(logits) >= 0.5).int() == y.int()).sum().item()\n",
        "print(f\"Val | loss={val_loss/len(val_loader):.4f} | acc={correct/len(ds_val):.4f}\")\n",
        "torch.save(model.state_dict(), f\"{save_dir}/best_{model_name}.pt\")\n",
        "print(\"Saved:\", f\"{save_dir}/best_{model_name}.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "id": "evaluate",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Evaluation & calibration\n",
        "test_loader = DataLoader(ds_test, batch_size=batch_size, shuffle=False)\n",
        "model.load_state_dict(torch.load(f\"{save_dir}/best_{model_name}.pt\", map_location=device))\n",
        "model.eval()\n",
        "\n",
        "all_y, all_p = [], []\n",
        "with torch.no_grad():\n",
        "    for x, y in test_loader:\n",
        "        p = torch.sigmoid(model(x.to(device)).squeeze(1)).cpu().numpy()\n",
        "        all_p.extend(p); all_y.extend(y.numpy())\n",
        "\n",
        "all_p = np.array(all_p); all_y = np.array(all_y)\n",
        "plot_confusion(all_y, (all_p >= 0.5).astype(int))\n",
        "plot_roc(all_y, all_p)\n",
        "reliability_diagram(all_y, all_p)\n",
        "print(\"ECE:\", expected_calibration_error(all_y, all_p))\n",
        "print(\"Brier:\", brier_score(all_y, all_p))\n",
        "_ = entropy_hist(all_p)"
      ]
    }
  ]
}
